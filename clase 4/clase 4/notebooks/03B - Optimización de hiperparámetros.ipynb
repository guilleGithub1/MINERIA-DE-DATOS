{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/Marca-ITBA-Color-ALTA.png\" width=\"250\">\n",
    "\n",
    "<h1>Master en Management & Analytics</h1>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clase 4 - Optimización de hiperparámetros - parte B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Referencias y bibliografía de consulta:\n",
    "\n",
    "- Introduction to Machine Learning with Python by Andreas C. Müller and Sarah Guido (O’Reilly) 2017 \n",
    "- An Introduction to Statistical Learning with Applications in R by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani (Springer) 2017 \n",
    "- Python Machine Learning - Second Edition by Sebastian Raschka (Packt) 2017\n",
    "- Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems - Aurélien Géron - 2017\n",
    "- https://scikit-learn.org/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/House sale.jpg\" width=\"400\"  >\n",
    "\n",
    "En la clase de hoy vamos a seguir trabajando con el [dataset](https://geodacenter.github.io/data-and-lab/KingCounty-HouseSales2015/) de precios de venta de viviendas del King County. \n",
    "\n",
    "Recordemos cuáles son los atributos del dataset y qué representa cada uno:\n",
    "Tenemos 21 atributos:\n",
    "- **id**: identificación\n",
    "- **date**: fecha de venta       \n",
    "- **price**: precio de venta. Esta es nuestra `variable objetivo`.\n",
    "- **bedrooms**: cantidad de habitaciones\n",
    "- **bathrooms**: cantidad de baños\n",
    "- **sqft_living**: tamaño de la zona habitable en pies cuadrados\n",
    "- **sqft_lot**: tamaño del lote en pies cuadrados\n",
    "- **floors**: cantidad de pisos\n",
    "- **waterfront**: 1' si la propiedad tiene un frente de agua, 0' si no.\n",
    "- **view**: un índice de 0 a 4 de lo buena que era la vista de la propiedad\n",
    "- **condition**: estado de la casa, clasificado del 1 al 5\n",
    "- **grade**: clasificación según la calidad de la construcción, que se refiere a los tipos de materiales utilizados y a la calidad de la mano de obra. Los edificios de mejor calidad (mayor grado) cuestan más de construir por unidad de medida y tienen mayor valor.\n",
    "- **sqft_above**: Pies cuadrados sobre el suelo\n",
    "- **sqft_basement**: Pies cuadrados bajo tierra\n",
    "- **yr_built**: año de construcción\n",
    "- **yr_renovated**: año de renovación. 0\" si no se ha renovado nunca\n",
    "- **zipcode**: código postal de 5 dígitos\n",
    "- **lat**: latitud\n",
    "- **long**: longitud\n",
    "- **sqft_living15**: tamaño medio del espacio habitable de las 15 casas más cercanas, en pies cuadrados\n",
    "- **sqft_lot15**: tamaño medio del lote de las 15 casas más cercanas, en pies cuadrados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a comenzar, como de costumbre importando algunas de las librerías que vamos a necesitar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un DataFrame tomando el csv con los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650     1.0           0     0  ...      7        1180              0   \n",
       "1      7242     2.0           0     0  ...      7        2170            400   \n",
       "2     10000     1.0           0     0  ...      6         770              0   \n",
       "3      5000     1.0           0     0  ...      7        1050            910   \n",
       "4      8080     1.0           0     0  ...      8        1680              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1951          1991    98125  47.7210 -122.319           1690   \n",
       "2      1933             0    98028  47.7379 -122.233           2720   \n",
       "3      1965             0    98136  47.5208 -122.393           1360   \n",
       "4      1987             0    98074  47.6168 -122.045           1800   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        5650  \n",
       "1        7639  \n",
       "2        8062  \n",
       "3        5000  \n",
       "4        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/kc_house_data.csv')\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a realizar las tareas de limpieza que hicimos la clase pasada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casteamos el atributo 'date' a datetime\n",
    "dataset['date'] = pd.to_datetime(dataset['date'])\n",
    "\n",
    "# Creamos una variable que represente el año de venta\n",
    "dataset['year_sold'] = dataset['date'].dt.year\n",
    "\n",
    "# Corregimos el error de carga en 'bedrooms'\n",
    "dataset.loc[dataset['bedrooms']==33,'bedrooms'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos nuestra matriz de features y nuestro vector target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X: (21613, 18)\n",
      "Type X: <class 'pandas.core.frame.DataFrame'>\n",
      "Shape y: (21613,)\n",
      "Type y: <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# Creamos X e y\n",
    "features_cols = [x for x in dataset.columns if x not in ['price','id', 'date','zipcode']]\n",
    "X = dataset[features_cols]\n",
    "y = dataset['price']\n",
    "\n",
    "# Verificamos el shape y el tipo de X e y:\n",
    "print(\"Shape X: {}\".format(X.shape))\n",
    "print(\"Type X: {}\".format(type(X)))\n",
    "print(\"Shape y: {}\".format(y.shape))\n",
    "print(\"Type y: {}\".format(type(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos el split entre train y test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs=1\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "         train_test_split(X, y, test_size=0.3, random_state=rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la imputación de las variables 'bedrooms' y 'bathrooms' para las casas con valores igual a 0, cuidando de calcular los valores en el set de entrenamiento y utilizando dichos valores para el train y test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['bedrooms'].replace(0, np.nan, inplace=True)\n",
    "X_train['bathrooms'].replace(0, np.nan, inplace=True)\n",
    "X_test['bedrooms'].replace(0, np.nan, inplace=True)\n",
    "X_test['bathrooms'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "X_train.fillna(X_train.groupby('floors').transform('median'), inplace=True)\n",
    "\n",
    "dicc_bed = X_train.groupby('floors')['bedrooms'].median().apply(np.ceil).to_dict()\n",
    "dicc_bath = X_train.groupby('floors')['bathrooms'].median().apply(np.ceil).to_dict()\n",
    "\n",
    "X_test['bedrooms'] = X_test['bedrooms']\\\n",
    "                            .fillna(X_test['floors'].apply(lambda x: dicc_bed.get(x)))\n",
    "\n",
    "X_test['bathrooms'] = X_test['bathrooms']\\\n",
    "                            .fillna(X_test['floors'].apply(lambda x: dicc_bath.get(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estandarización\n",
    "\n",
    "Un aspecto metodológico importante es que para aplicar estas técnicas de regularización, tenemos que normalizar los datos. Esto se debe a que, al penalizar los parámentros por su tamaño, la escala en la que están medidas las variables se vuelve absolutamente relevante.\n",
    "\n",
    "Con el modelo de regresión lineal sin regularización, el valor de los parámetros compensaba por las unidades de medida de las variables, por lo que no afectaba al resultado del modelo. Al aplicar regularización, no queremos que efectos de escala afecten la imporancia relativa de los parámetros. Por este motivo, estandarizamos a todas las variables, con media $0$ y desvío estándar $1$, de modo tal que de llevar a todas las variables a una escala común. \n",
    "\n",
    "Uno de los aspectos que tenemos que saber antes de entrenar un modelo de machine learning es si requiere o no que los datos estén normalizados.\n",
    "\n",
    "Apliquemos estandarización, transformando las variables para que tengan media 0 $(\\mu = 0)$ y desvío estándar 1 $(\\sigma = 1)$, aplicando la fórmula:\n",
    "\n",
    "$$ x' = \\frac{x - \\mu}{\\sigma}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "stdscaler = StandardScaler()\n",
    "\n",
    "X_train_std = pd.DataFrame(stdscaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_std = pd.DataFrame(stdscaler.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante notar que estamos haciendo el `fit_transform()` de `stdscaler` con los datos de entrenamiento. Para los datos de testeo, estamos usando el método `transform`, es decir que normalizamos utilizando las medias y desvíos estándar calculados en el set de testo. Esto es así para evitar **data leakage**, es decir filtración de información del set de testo en el modelo.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines (SVM)\n",
    "\n",
    "##### SVM es Modelo Discriminante: busca trazar una recta o curva divisoria en el espacio de features.\n",
    "\n",
    "SVM es un algoritmo que sirve para resolver tanto problemas de clasificación como regresión. \n",
    "\n",
    "\n",
    "Pensemos en un problema de clasificación. Queremos dividir las 2 clases. Existen muchas posibles líneas que podríamos trazar para dividir las dos clases ¿Cuál sería la mejor? \n",
    "\n",
    "<img src=\"img/svm1.png\" align=\"center\" width=\"400\"/>\n",
    "\n",
    "Dependiendo la línea que se elija, una nueva observación puede quedar en una u otra clase.\n",
    "\n",
    "Imaginen que trazamos un “margen” entre la línea discriminante y el punto más cercano de cada clase. Lo que hace el algoritmo SVM es encontrar **la línea discriminante que maximiza el ancho de este “margen”**.\n",
    "\n",
    "<img src=\"img/svm2.png\" align=\"center\" width=\"400\"/>\n",
    "\n",
    "Cuando ajustamos el modelo SVM a estos datos obtenemos la línea discriminante que se encuentra en el medio. Las líneas punteadas representan los límites del margen.\n",
    "\n",
    "Es importante notar que solamente algunos de los puntos tocan los límites del margen. Estos puntos son los “vectores de soporte”. A la hora de hacer el ajuste del modelo, los únicos puntos que importan son estos. \n",
    "El comportamiento de los que se encuentran lejos del “decision boundary” no tiene ninguna importancia.\n",
    "\n",
    "<img src=\"img/svm3.png\" align=\"center\" width=\"400\"/>\n",
    "\n",
    "##### ¿Qué pasa si no se puede hacer una división perfecta?\n",
    "\n",
    "Para resolver este problema, el algoritmo incorpora el parámetro C que permite que algunos puntos permanezcan dentro del margen para mejorar el ajuste.\n",
    "\n",
    "<img src=\"img/svm4.png\" align=\"center\" width=\"850\"/>\n",
    "\n",
    "##### El hiperparámetro C es uno los que regulariza el trade-off entre sesgo y varianza.\n",
    "\n",
    "C grande -> menos regularización -> menos tolerancia al error -> márgenes más chicos -> más varianza\n",
    "\n",
    "C chico -> más regularización -> más tolerancia al error -> márgenes más grandes -> más sesgo\n",
    "\n",
    "\n",
    "#### Kernel Trick\n",
    "\n",
    "Sin entrar demasiado en los detalles técnicos, es importante señalar que en SVM, la estimación del modelo implica el producto interno entre todas las observaciones. Recordemos que el producto interno entre 2 vectores nos da una medida de su similitud.\n",
    "\n",
    "<img src=\"img/inner_prod.png\" align=\"center\" width=\"350\"/>\n",
    "\n",
    "El SVM lineal puede representarse del siguiente modo:\n",
    "\n",
    "<img src=\"img/linear_kernel.png\" align=\"center\" width=\"350\"/>\n",
    "\n",
    "Reemplazando al producto interno con una generalización del tipo:\n",
    "\n",
    "<img src=\"img/kernel.png\" align=\"center\" width=\"200\"/>\n",
    "\n",
    "a la que llamamos `kernel`. El `kernel` es una función que cuantifica la similitud entre 2 observaciones. \n",
    "\n",
    "Podríamos en cambio utilizar un kernel polinómico:\n",
    "\n",
    "<img src=\"img/poly_kernel.png\" align=\"center\" width=\"400\"/>\n",
    "\n",
    "En esencia, se trata de ajustar un clasificador de vectores de soporte en un espacio de mayor dimensión que incluye polinomios de grado *d*, en lugar de hacerlo en el espacio de características original.\n",
    "\n",
    "Otra alternativa es el kernel radial:\n",
    "\n",
    "<img src=\"img/rbf_kernel.png\" align=\"center\" width=\"400\"/>\n",
    "\n",
    "La función kernel en SVM nos dice, dados dos puntos en el espacio de los datos original, cuál es su similitud en el espacio de las features. Permite evitar hacer la transformación de los datos al espacio de las features. Diferentes kernels corresponden a diferentes transformaciones de los datos.\n",
    "\n",
    "<img src=\"img/svm5.png\" align=\"center\" width=\"850\"/>\n",
    "\n",
    "Cuanto más chico es gamma, la función de similitud del kernel RBF cae más suavemente con la distancia entre los puntos y por lo tanto genera fronteras de decisión más suaves.\n",
    "\n",
    "<img src=\"img/svm6.png\" align=\"center\" width=\"850\"/>\n",
    "\n",
    "En la siguiente imagen podemos observar las fronteras de decisión de un kernel polinómico de grado 3 (izq.) y un kernel RBF para el mismo dataset:\n",
    "\n",
    "<img src=\"img/poly_rbf.png\" align=\"center\" width=\"750\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Búsqueda sobre espacios que no son grillas\n",
    "\n",
    "En algunos casos, probar todas las combinaciones posibles de todos los parámetros, como suele hacer `GridSearchCV`, no es una buena idea. Por ejemplo, SVM tiene un parámetro de `kernel`, y dependiendo del kernel que se elija, otros parámetros serán relevantes. Si kernel='linear', el modelo es lineal, y sólo se utiliza el parámetro C. Si kernel='rbf', se utilizan los parámetros C y gamma. En este caso, la búsqueda de todas las combinaciones posibles de C, gamma y kernel no tendría sentido.\n",
    "\n",
    "Para tratar este tipo de parámetros \"condicionales\", `GridSearchCV` permite que `param_grid` sea una lista de diccionarios. Cada diccionario de la lista se expande en una cuadrícula independiente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista de grillas:\n",
      "[{'kernel': ['rbf'], 'C': [1000, 10000, 100000, 1000000, 10000000], 'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}, {'kernel': ['linear'], 'C': [1000, 10000, 100000, 1000000, 10000000]}, {'kernel': ['poly'], 'C': [1000, 10000, 100000, 1000000, 10000000], 'degree': [2, 3, 4]}]\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{'kernel': ['rbf'],\n",
    "               'C': [1000, 10000, 100000, 1000000, 10000000],\n",
    "               'gamma': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "              {'kernel': ['linear'],\n",
    "               'C': [1000, 10000, 100000, 1000000, 10000000]},\n",
    "              {'kernel': ['poly'],\n",
    "               'C': [1000, 10000, 100000, 1000000, 10000000],\n",
    "               'degree': [2, 3, 4]}]\n",
    "\n",
    "print(\"Lista de grillas:\\n{}\".format(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best parameters: {'C': 10000000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Best cross-validation score: 0.81746\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(SVR(cache_size=500), param_grid, cv=3, scoring='r2', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train_std, y_train)\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.5f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 train GridSearchCV: 0.86332\n",
      "R2 test GridSearchCV: 0.82399\n"
     ]
    }
   ],
   "source": [
    "y_pred_train_grid = grid_search.predict(X_train_std)\n",
    "print ('R2 train GridSearchCV: {}'.format(r2_score(y_train,y_pred_train_grid).round(5)))\n",
    "\n",
    "y_pred_test_grid = grid_search.predict(X_test_std)\n",
    "print ('R2 test GridSearchCV: {}'.format(r2_score(y_test,y_pred_test_grid).round(5)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
