{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/Marca-ITBA-Color-ALTA.png\" width=\"250\">\n",
    "\n",
    "<h1>Master en Management & Analytics</h1>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clase 4 - Optimización de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Referencias y bibliografía de consulta:\n",
    "\n",
    "- Introduction to Machine Learning with Python by Andreas C. Müller and Sarah Guido (O’Reilly) 2017 \n",
    "- An Introduction to Statistical Learning with Applications in R by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani (Springer) 2017 \n",
    "- Python Machine Learning - Second Edition by Sebastian Raschka (Packt) 2017\n",
    "- Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems - Aurélien Géron - 2017\n",
    "- https://scikit-learn.org/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/House sale.jpg\" width=\"400\"  >\n",
    "\n",
    "En la clase de hoy vamos a seguir trabajando con el [dataset](https://geodacenter.github.io/data-and-lab/KingCounty-HouseSales2015/) de precios de venta de viviendas del King County. \n",
    "\n",
    "Recordemos cuáles son los atributos del dataset y qué representa cada uno:\n",
    "Tenemos 21 atributos:\n",
    "- **id**: identificación\n",
    "- **date**: fecha de venta       \n",
    "- **price**: precio de venta. Esta es nuestra `variable objetivo`.\n",
    "- **bedrooms**: cantidad de habitaciones\n",
    "- **bathrooms**: cantidad de baños\n",
    "- **sqft_living**: tamaño de la zona habitable en pies cuadrados\n",
    "- **sqft_lot**: tamaño del lote en pies cuadrados\n",
    "- **floors**: cantidad de pisos\n",
    "- **waterfront**: 1 si la propiedad tiene un frente de agua, 0 si no.\n",
    "- **view**: un índice de 0 a 4 de lo buena que era la vista de la propiedad\n",
    "- **condition**: estado de la casa, clasificado del 1 al 5\n",
    "- **grade**: clasificación según la calidad de la construcción, que se refiere a los tipos de materiales utilizados y a la calidad de la mano de obra. Los edificios de mejor calidad (mayor grado) cuestan más de construir por unidad de medida y tienen mayor valor.\n",
    "- **sqft_above**: Pies cuadrados sobre el suelo\n",
    "- **sqft_basement**: Pies cuadrados bajo tierra\n",
    "- **yr_built**: año de construcción\n",
    "- **yr_renovated**: año de renovación. 0 si no se ha renovado nunca\n",
    "- **zipcode**: código postal de 5 dígitos\n",
    "- **lat**: latitud\n",
    "- **long**: longitud\n",
    "- **sqft_living15**: tamaño medio del espacio habitable de las 15 casas más cercanas, en pies cuadrados\n",
    "- **sqft_lot15**: tamaño medio del lote de las 15 casas más cercanas, en pies cuadrados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a comenzar, como de costumbre importando algunas de las librerías que vamos a necesitar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un DataFrame tomando el csv con los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/kc_house_data.csv')\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a realizar las tareas de limpieza que hicimos la clase pasada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Casteamos el atributo 'date' a datetime\n",
    "dataset['date'] = pd.to_datetime(dataset['date'])\n",
    "\n",
    "# Creamos una variable que represente el año de venta\n",
    "dataset['year_sold'] = dataset['date'].dt.year\n",
    "\n",
    "# Corregimos el error de carga en 'bedrooms'\n",
    "dataset.loc[dataset['bedrooms']==33,'bedrooms'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos nuestra matriz de features y nuestro vector target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creamos X e y\n",
    "features_cols = [x for x in dataset.columns if x not in ['price','id', 'date','zipcode']]\n",
    "X = dataset[features_cols]\n",
    "y = dataset['price']\n",
    "\n",
    "# Verificamos el shape y el tipo de X e y:\n",
    "print(\"Shape X: {}\".format(X.shape))\n",
    "print(\"Type X: {}\".format(type(X)))\n",
    "print(\"Shape y: {}\".format(y.shape))\n",
    "print(\"Type y: {}\".format(type(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos el split entre train y test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rs=1\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "         train_test_split(X, y, test_size=0.3, random_state=rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la imputación de las variables 'bedrooms' y 'bathrooms' para las casas con valores igual a 0, cuidando de calcular los valores en el set de entrenamiento y utilizando dichos valores para el train y test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train['bedrooms'].replace(0, np.nan, inplace=True)\n",
    "X_train['bathrooms'].replace(0, np.nan, inplace=True)\n",
    "X_test['bedrooms'].replace(0, np.nan, inplace=True)\n",
    "X_test['bathrooms'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "X_train.fillna(X_train.groupby('floors').transform('median'), inplace=True)\n",
    "\n",
    "dicc_bed = X_train.groupby('floors')['bedrooms'].median().apply(np.ceil).to_dict()\n",
    "dicc_bath = X_train.groupby('floors')['bathrooms'].median().apply(np.ceil).to_dict()\n",
    "\n",
    "X_test['bedrooms'] = X_test['bedrooms']\\\n",
    "                            .fillna(X_test['floors'].apply(lambda x: dicc_bed.get(x)))\n",
    "\n",
    "X_test['bathrooms'] = X_test['bathrooms']\\\n",
    "                            .fillna(X_test['floors'].apply(lambda x: dicc_bath.get(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estandarización\n",
    "\n",
    "Un aspecto metodológico importante es que para aplicar estas técnicas de regularización, tenemos que normalizar los datos. Esto se debe a que, al penalizar los parámentros por su tamaño, la escala en la que están medidas las variables se vuelve absolutamente relevante.\n",
    "\n",
    "Con el modelo de regresión lineal sin regularización, el valor de los parámetros compensaba por las unidades de medida de las variables, por lo que no afectaba al resultado del modelo. Al aplicar regularización, no queremos que efectos de escala afecten la imporancia relativa de los parámetros. Por este motivo, estandarizamos a todas las variables, con media $0$ y desvío estándar $1$, de modo tal que de llevar a todas las variables a una escala común. \n",
    "\n",
    "Uno de los aspectos que tenemos que saber antes de entrenar un modelo de machine learning es si requiere o no que los datos estén normalizados.\n",
    "\n",
    "Apliquemos estandarización, transformando las variables para que tengan media 0 $(\\mu = 0)$ y desvío estándar 1 $(\\sigma = 1)$, aplicando la fórmula:\n",
    "\n",
    "$$ x' = \\frac{x - \\mu}{\\sigma}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "stdscaler = StandardScaler()\n",
    "\n",
    "X_train_std = pd.DataFrame(stdscaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_std = pd.DataFrame(stdscaler.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante notar que estamos haciendo el `fit_transform()` de `stdscaler` con los datos de entrenamiento. Para los datos de testeo, estamos usando el método `transform`, es decir que normalizamos utilizando las medias y desvíos estándar calculados en el set de testo. Esto es así para evitar **data leakage**, es decir filtración de información del set de testo en el modelo.  \n",
    "\n",
    "Corroboremos los valores de la media y el desvío estándar:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo base sin regularización\n",
    "\n",
    "Vamos a crear un modelo base sin regularización. Para poder apreciar el efecto de la regularización, este modelo debería tener un problema de overfitting. Vamos a tomar nuestra regresión lineal y vamos a crear variables polinómicas para un subset de las $features$, con el objetivo de llegar a tener un problema de sobreajuste que podamos mitigar con las técnicas de regularización que estamos estudiando. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train_pol = PolynomialFeatures(degree=3, include_bias=False).fit_transform(\\\n",
    "                      X_train_std[['sqft_living', 'grade', 'sqft_above','sqft_living15',\\\n",
    "                                  'bathrooms', 'view', 'sqft_basement', 'bedrooms']])\n",
    "\n",
    "X_train_no_pol = X_train_std[[x for x in X_train_std.columns if x not in ['sqft_living', \\\n",
    "                                 'grade', 'sqft_above','sqft_living15',\\\n",
    "                                  'bathrooms', 'view', 'sqft_basement', 'bedrooms']]].values\n",
    "\n",
    "X_train_feat_eng = np.concatenate((X_train_pol,X_train_no_pol), axis=1 )\n",
    "\n",
    "\n",
    "print('X_train_pol.shape: {}'.format(X_train_pol.shape))\n",
    "print('X_train_no_pol.shape: {}'.format(X_train_no_pol.shape))\n",
    "print('X_train_feat_eng.shape: {}'.format(X_train_feat_eng.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test_pol = PolynomialFeatures(degree=3, include_bias=False).fit_transform(\\\n",
    "                      X_test_std[['sqft_living', 'grade', 'sqft_above','sqft_living15',\\\n",
    "                                  'bathrooms', 'view', 'sqft_basement', 'bedrooms']])\n",
    "\n",
    "X_test_no_pol = X_test_std[[x for x in X_train_std.columns if x not in ['sqft_living', \\\n",
    "                                 'grade', 'sqft_above','sqft_living15',\\\n",
    "                                  'bathrooms', 'view', 'sqft_basement', 'bedrooms']]].values\n",
    "\n",
    "X_test_feat_eng = np.concatenate((X_test_pol,X_test_no_pol), axis=1 )\n",
    "\n",
    "\n",
    "print('X_test_pol.shape: {}'.format(X_test_pol.shape))\n",
    "print('X_test_no_pol.shape: {}'.format(X_test_no_pol.shape))\n",
    "print('X_test_feat_eng.shape: {}'.format(X_test_feat_eng.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr_base = LinearRegression(fit_intercept=True)\n",
    "\n",
    "lr_base.fit(X_train_feat_eng, y_train)\n",
    "\n",
    "y_pred_train = lr_base.predict(X_train_feat_eng)\n",
    "y_pred_test = lr_base.predict(X_test_feat_eng)\n",
    "\n",
    "print ('R2 train sin regularización: {}'.format(r2_score(y_train, y_pred_train).round(4)))\n",
    "print ('R2 test sin regularización: {}'.format(r2_score(y_test, y_pred_test).round(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización de hiperparámetros\n",
    "\n",
    "Llegamos al momento de preguntarnos cómo podemos hacer para seleccionar la **combinación óptima de hiperparámentros**.\n",
    "\n",
    "Por ahora, solamente vimos modelos simples para los que hay que definir algunos pocos hiperparámetros, pero para modelos más complejos vamos a tener que optimizar una gran cantidad de hiperparámetros, por lo que es necesario encontrar una forma de realizar la búsqueda de forma sistemática y poder confiar en los resultados obtenidos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Cross-validation\n",
    "\n",
    "Antes de avanzar, tenemos que introducir una técnica de validación: el **cross-validation** o **validación cruzada**. \n",
    "\n",
    "Cuando hacemos **cross-validation**, en lugar de separar el dataset entre set de entrenamiento y de testeo, **armamos múltiples sets de entrenamiento y validación a partir de un mismo conjunto de datos de entrenamiento**, de forma tal de poder realizar varias pruebas sobre distintos datos desconocidos por el modelo y así tener una mejor noción acerca de su capacidad de generalización.\n",
    "\n",
    "<img src=\"img/3foldCV.png\" align=\"center\" width=\"400\"/>\n",
    "<div class='epigraph' align=\"center\"><i>3-fold cross validation</i></div><br>\n",
    "\n",
    "Este esquema ilustra una estrategia de *cross validation* con 3 particiones o *folds*. Tomamos el dataset de entrenamiento y lo dividimos en tres partes de igual tamaño. En cada prueba, entrenamos con 2/3 de los datos y validamos con las observaciones restantes. \n",
    "\n",
    "Una ventaja de este enfoque es que usamos todos los datos para entrenar el modelo, sin necesidad de sacrificar datos en el set de entrenamiento. En general, trabajamos con 3, 5 o 10 *folds* de validación cruzada.\n",
    "\n",
    "Realizando múltiples *folds* le damos más robustez estadística al análisis ya que promediamos varios resultados con distintos sets de entrenamiento y validación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metodología de optimización de hiperparámetros\n",
    "\n",
    "Vamos a combinar todas las técnicas que vimos para describir la metodología para optimizar hiperparámentros:\n",
    "\n",
    "<img src=\"img/gs_crossval.png\" align=\"center\" width=\"600\"/>\n",
    "<div class='epigraph' align=\"center\"><i>Metodología de optimización de hiperparámetros</i></div><br>\n",
    "\n",
    "\n",
    "- Como primer paso, separamos los datos en set de entrenamiento y de testeo. Usaremos el set de testeo para evaluar el poder de generalización de nuestro modelo.\n",
    "- Usamos los datos del train set para entrenar el modelo. Seleccionaremos la mejor combinación de hiperparámetros a partir de una estrategia de cross-validation, buscando combinaciones de hiperparámentros con Grid Search o Random Search. \n",
    "- Por último, la mejor combinación de hiperparámetros la vamos a volver a entrenar con todo nuestro conjunto de datos de train y vamos a evaluar su poder de generalización con los datos de test que nos guardamos en el primer paso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1) Regresión Ridge con cross-validation\n",
    "\n",
    "Importemos la clase `Ridge` de `sklearn.linear_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Cross-validaiton` se implementa en `scikit-learn` utilizando la función `cross_val_score` del módulo `model_selection`. Los parámetros de la función `cross_val_score` son el modelo que queremos evaluar, los datos de entrenamiento y el vector con las etiquetas del *ground-truth*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que queremos evaluar 3 valores de *alpha* en una regresión Ridge. Como vimos en la sección teórica de la clase, no podemos evaluar en el set de testeo, porque en ese caso, la estimación que obtendríamos sobre la capacidad de generalización del modelo ya no sería insesgada. \n",
    "\n",
    "Veamos cómo haríamos con `cross-validation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alphas = [0.1, 1, 10, 100, 1000]\n",
    "dic_scores = dict()\n",
    "\n",
    "for alpha in alphas:\n",
    "    rlr = Ridge(alpha=alpha)\n",
    "    scores = cross_val_score(rlr, X_train_feat_eng, y_train, cv=3)\n",
    "    dic_scores.update({alpha: scores.mean()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos el diccionario con los scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dic_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos una Regresión Ridge en todo el dataset de entrenamiento utilizando el valor óptimo de *alpha*, y ahora evaluamos sobre el set de testeo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rlr = Ridge(alpha=max(dic_scores, key=dic_scores.get))\n",
    "\n",
    "rlr.fit(X_train_feat_eng, y_train)\n",
    "\n",
    "y_pred_train_ridge = rlr.predict(X_train_feat_eng)\n",
    "y_pred_test_ridge = rlr.predict(X_test_feat_eng)\n",
    "\n",
    "print (f\"R2 train Ridge: {(r2_score(y_train, y_pred_train_ridge).round(4))}\")\n",
    "print (f\"R2 test Ridge: {(r2_score(y_test,y_pred_test_ridge).round(4))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Grid Search y Random Search\n",
    "\n",
    "Veremos dos grandes métodos (no los únicos) de búsqueda de hiperparámetros:\n",
    "\n",
    "- **Grid Search**: se busca encontrar el mejor hiperparámetro dentro de una “grilla” (grid) de valores que definimos. Este método realiza una búsqueda exhaustiva dentro del espacio de hiperparámetros definido para buscar la combinación que optimice la función objetivo del modelo. \n",
    "- **RandomSearch** dado que el GridSearch implica una búsqueda exhaustiva de todas las combinaciones posibles de la grilla de hiperparámetros especificada, su ejecución pude volverse computacionalmente muy intensa. Con la estrategia de Random Search se realiza la búsqueda de la mejor combinación de hiperparámetros pero a partir de seleccionar en forma aleatoria un subset de los hiperparámetros, lo que achica el espacio de búsqueda.\n",
    "\n",
    "\n",
    "<img src=\"img/gsvsrs.png\" align=\"center\" width=\"500\"/>\n",
    "<div class='epigraph' align=\"center\"><i>Grid Search vs. Random Search</i></div><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1) ElasticNet con Grid Search \n",
    "\n",
    "Importemos la clase `ElasticNet` de `sklearn.linear_model`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de `ElasticNet`, tenemos que definir 2 hiperparámetros. Podemos ingresar a la documentación de la clase para ver de qué manera está implementada la combinación entre `Ridge` y `Lasso` y como ingresan ambos hiperparámetros al modelo. \n",
    "\n",
    "`ElasticNet` minimiza la siguiente función objetivo:\n",
    "\n",
    "        1 / (2 * n_samples) * ||y - Xw||^2_2\n",
    "        + alpha * l1_ratio * ||w||_1\n",
    "        + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementamos Grid Search\n",
    "\n",
    "Vamos a implementar las técnicas de optimización de hiperparámentros. `Sklearn` nos provee clases que nos permiten implementarlas facilmente. \n",
    "\n",
    "Para aplicar `Grid Search` en combinación con `cross-validation` disponemos de la clase `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Vamos a entrenar una regresión ElasticNet. Tenemos que instanciarla y \n",
    "# guardar el modelo en un objeto. \n",
    "elr = ElasticNet(max_iter=10000)\n",
    "\n",
    "# Definimos el espacio de búsqueda de hiperparámetros con un diccionario:\n",
    "param_grid = {'alpha':[0.9, 1.0, 1.1],\n",
    "             'l1_ratio':np.linspace(0.4, 0.6, 3)}\n",
    "\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciamos la clase `GridSearchCV` y la almacenamos en el objeto `grid`. \n",
    "\n",
    "Al instanciar la clase le tenemos que pasar:\n",
    "\n",
    "- El modelo que vamos a optimizar: `elr`\n",
    "- El espacion de búsqueda de hiperparámetros: `param_grid`\n",
    "- La estrategia de validación cruzada. Si no pasamos nada, por default serán 5 folds\n",
    "- El scoring. Por default toma el scoring de la clase del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_feat_eng = stdscaler.fit_transform(X_train_feat_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_jobs = cpu_count() // 2\n",
    "\n",
    "grid = GridSearchCV(elr, param_grid, cv=3, scoring='r2', n_jobs=n_jobs, verbose=3)\n",
    "grid.fit(X_train_feat_eng, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_train_grid = grid.predict(X_train_feat_eng)\n",
    "print ('R2 train GridSearchCV:', r2_score(y_train,y_pred_train_grid).round(5))\n",
    "\n",
    "y_pred_test_grid = grid.predict(X_test_feat_eng)\n",
    "print ('R2 test GridSearchCV:', r2_score(y_test,y_pred_test_grid).round(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analizamos los resultados del Grid Search\n",
    "\n",
    "Los resultados del Grid Search se pueden encontrar en el atributo `cv_results_`, que es un diccionario que almacena todos los aspectos de la búsqueda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results= pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos analizar la variación del score en el set de validación al variar los valores de los hiperparámetros con una pivot a la que vamos a visualizar con un mapa de calor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = results[['mean_test_score', 'param_alpha', 'param_l1_ratio']]\n",
    "scores = scores.pivot('param_alpha', 'param_l1_ratio', 'mean_test_score')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(scores, annot=True, fmt=\".3\", cmap=\"viridis\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que a medida que `alpha` se reduce, mejora el score. Lo contrario sucede con `l1_ratio`. Esto podría indicar que nuestra primera aproximación a `alpha`fue muy alta y, por el contrario, la de `l1_ratio` fue muy baja. \n",
    "\n",
    "Utilizemos esta información para buscar mejorar la performance del modelo utilizando `Random Search`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementamos Random Search\n",
    "\n",
    "Para aplicar `Random Search` en combinación con `cross-validation` disponemos de la clase `RandomizedSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_random = {'alpha':np.linspace(0.6,0.9,10).round(3),\n",
    "             'l1_ratio':np.linspace(0.6,0.9,10).round(3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomcv = RandomizedSearchCV(elr, param_random, n_iter=9, cv=3, scoring='r2',\\\n",
    "                              random_state=15, n_jobs=-1, verbose=1)\n",
    "randomcv.fit(X_train_feat_eng, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(randomcv.best_estimator_)\n",
    "print(randomcv.best_score_)\n",
    "print(randomcv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_random = randomcv.predict(X_train_feat_eng)\n",
    "print ('R2 train RandomizedSearchCV:', r2_score(y_train,y_pred_train_random).round(5))\n",
    "\n",
    "y_pred_test_random = randomcv.predict(X_test_feat_eng)\n",
    "print ('R2 test RandomizedSearchCV:', r2_score(y_test,y_pred_test_random).round(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
